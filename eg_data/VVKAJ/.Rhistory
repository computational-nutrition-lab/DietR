SpecifyDataDirectory(directory.name = "eg_data/NHANES/PF/Waist2")
totals <- read.delim("Total_D12_FC_QC_mean_QC_demo_ga_body_meta_n3642.txt")
# This should have 3,677 people.
nrow(totals)
# Load the food items data where QC-ed individuals were removed based on their totals data.
food <- read.delim("../../Food_D12_FC_QC_demo_QCed.txt", sep= "\t", header=T)
# Count the number of unique SEQNs. There should be 4207 people.
length(unique(food$SEQN))
# Load the food items data where QC-ed individuals were removed based on their totals data.
food <- read.delim("../../Food_D12_FC_QC_demo_QCed.txt", sep= "\t", header=T)
# Count the number of unique SEQNs. There should be 3642 people.
length(unique(food$SEQN))
# So need to only keep the individuals that are in totals (n=3642).
food2<- food[ food$SEQN %in% totals$SEQN, ]
# Should be 3677 SEQNs in food2.
length(unique(food2$SEQN))
# Here, we are interested in food items with their foodcode tarting from 4; nuts/seeds/legumes.
# Select only the rows that contain those food items.
food4s <- subset(food2, Food_code > 39999999 & Food_code < 50000000)
# Check that the subsetted data only contains 4xxxxxxxs.
summary(food4s$Food_code)
# Check the summary of the subset data.
paste(length(unique(food4s$SEQN)), "people consumed",
nrow(food4s), "food items with duplicates.",
"There are", length(unique(food4s$Food_code)), "unique food items.")
# Save as a txt file.
write.table(food4s, "Food_D12_FC_QC_demo_QCed_n3642_4s.txt", sep= "\t", row.names=F,quote=F)
MakeFoodTree(nodes_fn="../../../Food_tree_eg/NodeLabelsMCT.txt",
addl_foods_fn = NULL,
num.levels = 3,
food_database_fn =            "Food_D12_FC_QC_demo_QCed_n3642_4s.txt",
output_tree_fn =     "Foodtree/Food_D12_FC_QC_demo_QCed_n3642_4s_3Lv.nwk",
output_taxonomy_fn = "Foodtree/Food_D12_FC_QC_demo_QCed_n3642_4s_3Lv.tax.txt"
)
# --------------------------------------------------------------------------------------------------------------
# Generate IFC tables for downstream analyses; IT MAY TAKE SOME TIME.
# It is OK to see the following warning message:
# In write.table(fiber.ifc, output_fn, sep = "\t", quote = F, append = TRUE) :
# appending column names to file.
MakeFoodIfc(food_records_fn=  "Food_D12_FC_QC_demo_QCed_n3642_4s.txt",
food_record_id =  "SEQN",                              # The ID of your participants
food_taxonomy_fn= "Foodtree/Food_D12_FC_QC_demo_QCed_n3642_4s_3Lv.tax.txt",       # Your taxonomy file produced by MakeFoodTree.
output_fn =       "Foodtree/Food_D12_FC_QC_demo_QCed_n3642_4s_3Lv.food.ifc.txt")  # Output ifc file to be saved.
# Load the generated IFC table.
ifc <- read.delim("Foodtree/Food_D12_FC_QC_demo_QCed_n3642_4s_3Lv.food.ifc.txt")
# It should have the dimension of number of unique foods x (1 food column + number of people + 1 taxonomy column).
# 237 x 1839, in this case.
dim(ifc)
# The column names have "X." at the beginning. We will take care of it later.
ifc[1:4, 1:4]
source("lib/specify_data_dir.R")
# Name your main directory for future use.
main_wd <- file.path(getwd())
# Specify the directory where the data is.
SpecifyDataDirectory(directory.name = "eg_data/NHANES/PF/Waist2")
# Set your working directory to the main directory.
# Session --> Set working directory --> Choose directory.
setwd("~/GitHub/DietR")
source("lib/specify_data_dir.R")
# Name your main directory for future use.
main_wd <- file.path(getwd())
# Specify the directory where the data is.
SpecifyDataDirectory(directory.name = "eg_data/NHANES/PF/Waist2")
ifc <- read.delim("~/GitHub/DietR/eg_data/NHANES/PF/Waist2/Foodtree/Food_D12_FC_QC_demo_QCed_n3642_4s_3Lv.food.ifc.txt")
dim(ifc) # 237 x 1839
dim(ifc) # 237 x 1825
ifc[, c('X83767','X.FOODID')]  # 11 + 2.92 = 13.92 g. Has both Day 1 and Day 2.
ifc[, c('X92254','X.FOODID')]  # 3004.38  + 47.25 = 3051.63 g.
# Calculate the sum of 4xxxxxxx foods for each SEQN. This is the sum of two days.
head(colnames(ifc)) # X.FOODID, X87496, X88725, ...
tail(colnames(ifc)) # X92316, ..., taxonomy.
ifc[1:4, 1:4]
# exclude the food description and taxonomy columns.
colsum <- colSums(ifc[, 2: (ncol(ifc)-1) ] , na.rm=T)
head(colsum) # This is a named vector.
length(colsum)  # 1837 unique items
head(colsum) # This is a named vector.
min(colsum)
# Create a dataframe with SEQN and amount (2 days).
colsumdf <- data.frame(SEQN=names(colsum), amt = colsum)
row.names(colsumdf) <- NULL
head(colsumdf)
length(unique(colsumdf$SEQN))
# Safety check.
colsumdf %>% filter(SEQN=="X83767") # 13.92. Correct!
colsumdf %>% filter(SEQN=="X92254") # 3051.63. Correct! But this person seems to be an outlier...
# Divide the amount by 2 to get the average/day for each SEQN.
colsum_s <- colsumdf[order(colsumdf$amt, decreasing=T), ]
colsum_s$amt_ave <- colsum_s$amt/2 # divide by 2 and it will be average amount (g)/ day.
head(colsum_s)
colnames(colsum_s)[1] <- "XSEQN" # Change SEQN to XSEQN.
# Safety check.
colsum_s %>% filter(amt==0) %>% nrow() # all of the people have some consumption, OK!
# Look for outliers.
colsum_s %>% filter(amt== max(colsum_s$amt)) # The max is 1525 g/day.. by X92254.
# What did X92254 report eating?
ifc[, c('X92254','X.FOODID')]
# Load the all food data.
food <- read.delim("../../Food_D12_FC_QC_demo_QCed.txt", sep= "\t", header=T)
# Take out X92254 and have a look.
subsetted92254 <- subset(food, SEQN=="92254")
subsetted92254[ order(subsetted92254$FoodAmt, decreasing = T),  c("Day", "FoodAmt", "Main.food.description")]
# Take out X92254 and have a look.
subsetted92254 <- subset(food, SEQN=="92254")
subsetted92254[ order(subsetted92254$FoodAmt, decreasing = T),  c("Day", "FoodAmt", "Main.food.description")]
# Filter out "X92254" who ate 3 kg of nuts/seeds/legumes over 2 days.
colsum_s_2 <- colsum_s %>% filter(amt_ave < 1000)
max(colsum_s_2$amt_ave)
hist(colsum_s_2$amt_ave)
boxplot(colsum_s_2$amt_ave)
summary(colsum_s_2$amt_ave)
plot(colsum_s_2$amt_ave)
head(colsum_s_2)
# Save colsum_s_2.
write.table(colsum_s_2, "n3641_SEQN_4xxxxxx_amt.txt", sep="\t", row.names = F, quote=F)
# Define the col number.
coln <- which(colnames(ifc) == "X92254")
# Exclude the column of the outlier.
ifc2 <- ifc[, -coln]
ifc2$X92254 # NULL.
# Save the IFC table without the outlier.. n=3676.
write.table(ifc2, "Foodtree/Food_D12_FC_QC_demo_QCed_n3641_4s_3Lv.food.ifc.txt",
sep="\t", row.names = F, quote=F)
totals <- read.delim("Total_D12_FC_QC_mean_QC_demo_ga_body_meta_n3642.txt")
totals2 <- filter(totals, SEQN != "92254")
nrow(totals)
nrow(totals2)
write.table(totals2, "Total_D12_FC_QC_mean_QC_demo_ga_body_meta_n3641.txt",
sep="\t", row.names = F, quote=F)
# ---------------------------------------------------------------------------------------------------------------
# Read in the food data with 4s only. n3677, which means the outlier IS included, and needs to be removed.
food4s <- read.delim("Food_D12_FC_QC_demo_QCed_n3642_4s.txt")
# Exclude this outlier individual 92254 from the food data, and count the number of foods.
food4s_woOutlier <- subset(food4s, SEQN !="92254")
tail(food4s_woOutlier,1)
length(unique(food4s_woOutlier$Food_code)) # 237 unique foods, OK.
length(unique(food4s_woOutlier$Main.food.description))  # 237 unique foods, OK.
length(unique(food4s_woOutlier$SEQN))
length(unique(food4s_woOutlier$Food_code)) # 237 unique foods, OK.
length(unique(food4s_woOutlier$Main.food.description))  # 237 unique foods, OK.
# Count how many foods were reported by n=3676 (without the outlier) including duplicates?
length(food4s_woOutlier$Food_code)
# Count how many foods were reported by n=3641 (without the outlier) including duplicates?
length(food4s_woOutlier$Food_code)
# Save the food data of n=3641.
write.table(food4s_woOutlier, "Food_D12_FC_QC_demo_QCed_n3641_4s.txt",
sep="\t", row.names = F, quote=F)
# Set your working directory to the main directory.
# Session --> Set working directory --> Choose directory.
setwd("~/GitHub/DietR")
source("lib/specify_data_dir.R")
source("lib/diversity_nth_tile.R")
# Name your main directory for future use.
main_wd <- file.path(getwd())
# Specify the directory where the data is.
SpecifyDataDirectory(directory.name = "eg_data/NHANES/PF/Waist2")
library(vegan)
ifc_QCed <- read.delim("Foodtree/Food_D12_FC_QC_demo_QCed_n3641_4s_3Lv.food.ifc.txt")
ifc_QCed[1:4, 1:4]
# Take out the foodID (description) and taxonomy from ifc.
ifc2 <- ifc_QCed[, 2: (ncol(ifc_QCed)-1) ]
# transpose so that the SEQN will come to rows.
ifc2t <- as.data.frame(t(ifc2))
# Add taxonomy as the column names of ifc2t.
colnames(ifc2t) <- ifc$X.FOODID
# Make a table to save results.
SEQNdiv <- as.data.frame(matrix(nrow = nrow(ifc2t) , ncol = 4))
colnames(SEQNdiv) <- c("SEQN", "Shannon", "Simpson", "Invsimpson")
for( i in 1: nrow(ifc2t) ){
SEQNdiv[i, 1] <- rownames(ifc2t)[i]
SEQNdiv[i, 2] <- diversity(ifc2t[i, ], 'shannon')
SEQNdiv[i, 3] <- diversity(ifc2t[i, ], 'simpson')
SEQNdiv[i, 4] <- diversity(ifc2t[i, ], 'invsimpson')
}
head(SEQNdiv)
# There should be no NA values.
table(is.na(SEQNdiv), useNA="always")
# Plot histograms of each of the diversity measures.
par(mfrow = c(2, 2))
hist(SEQNdiv$Shannon, main="Shannon diversity", xlab="", breaks=15)
hist(SEQNdiv$Simpson, main="Simpson diversity", xlab="", breaks=15)
hist(SEQNdiv$Invsimpson, main="Invsimpson diversity", xlab="", breaks=15)
par(mfrow = c(1, 1))
# Remove the "X" in the SEQNdiv$SEQN for merging.
SEQNdiv$SEQN <- gsub(SEQNdiv$SEQN, pattern = "X", replacement = "")
# Load totals without the outlier (SEQN==92254).
totals <- read.delim("Total_D12_FC_QC_mean_QC_demo_ga_body_meta_n3641.txt")
# First, need to add the diversity values to totals. Only take the rows present in both datasets.
totals_div <- merge(totals, SEQNdiv, by='SEQN')
# ---------------------------------------------------------------------------------------------------------------
# Select individuals whose diversity score is > 0, and group them into groups lower and upper (2-tiles)
# based on their Shannon's diversity measure.
DivNthTile(input= totals_div, div.var="Shannon", nth.tile=2)
# Define Div1 and Div2.
out$DivGroup <-
ifelse(
out$Div == 1,
out$DivGroup <- 'Div1',
out$DivGroup <- 'Div2'
)
# Select only the SEQN and DivGroup.
SEQN_Div12 <- out[, c("SEQN", "DivGroup")]
# Define Div0. ----------------------------------------
# Subset those that have Shannon index =0.
totals_div_zero <- subset(totals_div, Shannon == 0)
# Add DivGroup variable, and insert "Div0".
totals_div_zero$DivGroup <- 'Div0'
# Select only the SEQN and DivGroup.
SEQN_Div0 <- totals_div_zero[, c("SEQN", "DivGroup")]
# Define DivNA. ----------------------------------------
# Define "Not in" function.  By default it's not existent.
`%!in%` <- Negate(`%in%`)
# Subset those that are not in SEQNdiv.
# Those are the ones that did not consume nuts/seeds/legumes.
totals_not_in_SEQNdiv <- totals[totals$SEQN %!in% SEQNdiv$SEQN, ]
# Add DivGroup variable, and insert "DivNA".
totals_not_in_SEQNdiv$DivGroup <- 'DivNA'
# Take only the SEQN and DivGroup.
SEQN_DivNA <- totals_not_in_SEQNdiv[, c("SEQN", "DivGroup")]
# ---------------------------------------------------------------------------------------------------------------
# Combine SEQN_DivNA, SEQN_Div0, and SEQN_Div12 for merging.
SEQN_Div_NA_012 <- rbind(SEQN_DivNA, SEQN_Div0, SEQN_Div12)
# Check that this should have the same number of rows as totals does.
identical(length(unique(SEQN_Div_NA_012$SEQN)), nrow(totals))
# Moreover, check that the ordered SEQN of SEQN_Div_NA_012 and totals are the same.
identical( unique(SEQN_Div_NA_012$SEQN)[order(unique(SEQN_Div_NA_012$SEQN))],
unique(totals$SEQN)         [order(unique(totals$SEQN))])
# Merge DivGroups with the totals.
totals_divgroup <- merge(totals, SEQN_Div_NA_012, all.x=T, by="SEQN")
# Change DivGroup into a factor and specify the factor levels.
totals_divgroup$DivGroup <- factor(totals_divgroup$DivGroup,
levels = c('DivNA', 'Div0', 'Div1', 'Div2') )
# The individuals in totals were grouped into 4 groups depending on their consumption of
# 4xxxxxxx foods (or the lack thereof). The totals_divgroup has DivGroup column.
table(totals_divgroup$DivGroup, useNA = "ifany")
# Save the totals with DivGroup.
write.table(totals_divgroup, "Total_D12_FC_QC_mean_QC_demo_ga_body_meta_n3641_DivGroup.txt",
sep="\t", row.names=F, quote=F)
# ===============================================================================================================
# Waist2.
# Draw a boxplot of nuts/seeds/legumes amount and DivGroup
# Version 1
# Created on 05/19/2023 by Rie Sadohara
# Replaced "n3676" with "n3641" o on 06/28/2023 by Rie Sadohara
# Output as comments were updated.
# ===============================================================================================================
library(ggplot2)
# Set your working directory to the main directory.
# Session --> Set working directory --> Choose directory.
setwd("~/GitHub/DietR")
source("lib/specify_data_dir.R")
source("lib/ggplot2themes.R")
# Name your main directory for future use.
main_wd <- file.path(getwd())
# Specify the directory where the data is.
SpecifyDataDirectory(directory.name = "eg_data/NHANES/PF/Waist2")
colsum_s_2 <- read.delim("n3641_SEQN_4xxxxxx_amt.txt")
head(colsum_s_2)
totalsDiv <- read.delim("Total_D12_FC_QC_mean_QC_demo_ga_body_meta_n3641_DivGroup.txt")
totalsDiv[1:4, 1:4]
totalsDiv$XSEQN <- paste("X", totalsDiv$SEQN, sep="")
# Add DivGroup to colsum_s_2 by XSEQN.
colsum_s_2_div <- merge(colsum_s_2, totalsDiv, all.x = T, by="XSEQN")
# Check.
table(colsum_s_2_div$DivGroup, useNA = "ifany")
head(colsum_s_2_div$amt_ave)
# ---------------------------------------------------------------------------------------------------------------
# Plot the amount by DivGroup.
box <-
ggplot(data= colsum_s_2_div, aes(x=DivGroup, y= amt_ave, fill=DivGroup)) +
geom_boxplot( outlier.shape=16, outlier.alpha=0.5  ) + space_axes + no_grid +
# scale_fill_manual(values= c("steelblue3", "yellow", "hotpink") ) +
labs(y="Nuts/seeds/legumes (g/day)", x=NULL)
box
ggsave("n3641_SEQN_4xxxxxx_amt_ave_DivGroup.png", box,
device="png", width=5.2, height=4.2, units="in")
setwd("~/GitHub/DietR")
# Name your main directory where input files are pulled.
main_wd <- file.path(getwd())
# Import source code to run the analyses to follow.
source("lib/specify_data_dir.R")
source("lib/load_clean_ASA24.R")
source("lib/average.by.R")
source("lib/QCOutliers.R")
source("lib/Food_tree_scripts/format.foods_2.r")
# You can come back to the main directory by:
setwd(main_wd)
# ===============================================================================================================
# Load ASA24 data
# ===============================================================================================================
# Specify the directory where the data is.
SpecifyDataDirectory(directory.name= "eg_data/VVKAJ/")
# Load your unprocessed (raw) food items-level data (as downloaded from the ASA24 study website).
# The csv file will be loaded as a dataframe in R and be named as items_raw.
items_raw <- read.csv("Raw_data/VVKAJ_Items.csv", sep = ",", header=T)
# items_raw has a column called "Food_Description", but this needs to be changed to "Main.food.description".
# Change the column name.
names(items_raw)[names(items_raw) == "Food_Description"] <- "Main.food.description"
# Check if any column names match with "Main.food.description". If there is a match, it will be printed.
names(items_raw)[names(items_raw) == "Main.food.description"]
# [Note] The numbers in the square brackets of the output indicate the sequential number of each element to
# help count the number of elements.
# Save the items file as a .txt file. This command saves the object "items_raw" as a .txt file with
# the specified filename using the write.table function.
write.table(items_raw, "VVKAJ_Items.txt", sep="\t", row.names=F)
# Special characters common in food names in dietary data such as "'", ",", "%" may interfere correct
# data loading in R; thus, we replace them with an underscore "_".
# Format foods so that special characters will be replaced with "_". "_f" stands for "formatted".
FormatFoods(input_fn =  "VVKAJ_Items.txt",
output_fn = "VVKAJ_Items_f.txt")
# [Note] It is best practice to avoid overwriting your raw data. Always save formatted/manipulated versions
# as a new file as described above.
# Load the Items_f.txt file to take a look at it.
# You need the "quote=""" and "colClasses="character"" arguments to ignore quotation marks (do not regard them
# as a cell separator) and to load all the columns as characters so that FoodID will keep the trailing ".0".
items_f <- read.delim("VVKAJ_Items_f.txt", quote="", colClasses="character")
# All special characters in the items data should have been replaced with an underscore in the Main.foood.description
# column, the 3rd from the last column of the items_f. We can confirm that by using the head function, which shows the
# first six rows of the specified dataset by default.
head(items_f)
# Add a human-readable sample identifier (SampleID) with a desired prefix, and save it as a txt file. SampleIDs
# are IDs unique to each combination of users and day and represent days of dietary intake in this dataset.
AddSampleIDtoItems(input.fn="VVKAJ_Items_f.txt", user.name="UserName", recall.no="RecallNo",
prefix="vvkaj.", out.fn="VVKAJ_Items_f_id.txt")
# Load the formatted Items file with SampleID added.
items_f_id <- read.delim("VVKAJ_Items_f_id.txt", quote="", colClasses="character")
# A combination of the specified prefix and sequential number (vvkaj.00001) should be added in the SampleID
# column, the first column of the items_f_id dataframe. You will probably need to scroll up the output a
# little bit in the console to view the first column.
head(items_f_id)
# Ensure your items file has the expected dimensions (number of rows x number of columns,
# shown as number of obs. and number of variables) in the environment window of R Studio.
# Or by using dim(items_f_id) and dim(items_raw). Note that items_f_id has 3 more columns
# than items_raw because new columns of FoodID, Old.Main.food.description, and SampleID have been added.
dim(items_f_id)
dim(items_raw)
# ===============================================================================================================
# Use individuals_to_remove.txt to filter out users marked as Remove = yes.
# ===============================================================================================================
# Optionally, if you know a certain user(s) should be removed, you can supply a metadata with two columns:
# UserName and "Remove", where the user(s) to be removed are marked "yes".
# Load your metadata that has information about which UserName(s) to remove.
ind_to_rm <- read.delim("individuals_to_remove.txt")
ind_to_rm
# Metadata for this purpose (ind_to_rm) has UserName and which one to be removed:
#     UserName Remove
# 1   VVKAJ101
# 2   VVKAJ102
# ... ...
# ... ...
# 16  VVKAJ116   yes
# 17  VVKAJ117
# Show which has "yes" in the "Remove" column.
subset(ind_to_rm, Remove == "yes")
# As shown in the console, the user named "VVKAJ116" is marked to be removed. VVKAJ116 has only 1 day of data,
# which may not be complete, thus it is marked as an individual to remove.  However, be careful when
# deleting a datapoint from your study and never remove individuals from the raw dataset, to ensure you
# can always go back and include them if desired.
# Remove the specified individuals.
# The output will be saved as a text file with the specified name.
# This assumes the usernames are in UserName column, and will print which user(s) will be removed.
RemoveRows(data=items_f_id, metadata.file= ind_to_rm,
output.name= "VVKAJ_Items_f_id_s.txt")
# Load the output for further processing.
items_f_id_s <- read.delim("VVKAJ_Items_f_id_s.txt", quote="", colClasses="character")
# Show unique usernames in items_f_id_s and confirm "VVKAJ116" has been removed.
unique(items_f_id_s$UserName)
# ===============================================================================================================
#  Merge individuals' metadata to items.
# ===============================================================================================================
# ind_metadata has the participants' gender, age, height, weight, BMI, and Waist.Circumference, etc.
# If desired, this individual-specific information can be added to items data.
# Load ind_metadata.txt.
ind_metadata <- read.table("ind_metadata.txt", sep="\t", header=T)
# Look at what the metadata has.
head(ind_metadata)
# This includes information on the removed individual, VVKAJ116, but it will not be used
# if VVKAJ116 is not in the items data.
# Add this metadata of each participant to totals or items.
# 'NA' will be inserted to UserNames which are not in ind_metadata.
items_f_id_s_m <- merge(x=items_f_id_s, y=ind_metadata, by="UserName", all.x=T)
# Check that the items data and metadata are merged.
head(items_f_id_s_m)
# Furthermore, as a quick way to look at the metadata of only the selected individuals, you can subset the
# metadata to just the usernames present in the analysis dataset (items_f_id_s) using the "%in%" operator.
ind_metadata_s <- ind_metadata[ind_metadata$UserName %in% items_f_id_s$UserName, ]
# Use the tail function to show the last six rows of ind_metadata_s. You can see that the last individual
# in this metadata is now VVKAJ117, and that VVKAJ116, which was not in items_f_id_s, has been omitted.
tail(ind_metadata_s)
# Save the merged dataframe as a .txt file.
write.table(items_f_id_s_m, "VVKAJ_Items_f_id_s_m.txt", sep="\t", row.names=F, quote=F)
# Use one of the input files saved above as an input for calculating totals for.
# Specify which columns have usernames and Recall.No., which has the recorded days.
GenerateTotals(inputfn =   "VVKAJ_Items_f_id_s_m.txt",
User.Name = "UserName",
Recall.No = "RecallNo",
outfn =     "VVKAJ_Tot.txt")
# Load the total file generated above.
new_totals <- read.table("VVKAJ_Tot.txt", header=T, sep="\t")
# The number of rows should be {No. of users x No. days}.
# For the example data, 16 users x 3 days = 48 rows (observations).
nrow(new_totals)
# View the new_totals.
head(new_totals)
# Load ind_metadata.txt if you have not done so.
ind_metadata <- read.table("ind_metadata.txt", sep="\t", header=T)
# Add this metadata of each participant to totals.
# 'NA' will be inserted to UserNames which are not in ind_metadata.
new_totals_m <- merge(x=new_totals, y=ind_metadata, by="UserName", all.x=T)
# Check that the items data and metadata are merged.
head(new_totals_m)
# Save the merged dataframe as a .txt file.
write.table(new_totals_m, "VVKAJ_Tot_m.txt", sep="\t", row.names=F, quote=F)
# Calculate the mean of the totals data across all the days for each participant.
AverageBy(data= new_totals, by= "UserName", start.col= "FoodAmt", end.col= "A_DRINKS",
outfn="VVKAJ_Tot_mean.txt")
# Load the output for further processing.
new_totals_mean <- read.table("VVKAJ_Tot_mean.txt", header=T, sep="\t")
# The number of rows should be equal to the number of users.
# This example data has 16 users, so there should be 16 rows of mean totals.
nrow(new_totals_mean)
# ===============================================================================================================
# Load ind_metadata.txt if you have not done so.
ind_metadata <- read.table("ind_metadata.txt", sep="\t", header=T)
# Add this metadata of each participant in the mean totals.
# 'NA' will be inserted to UserNames which are not in ind_metadata.
new_totals_mean_m <- merge(x=new_totals_mean, y=ind_metadata, by="UserName", all.x=T)
# Check that the mean totals and the users' metadata are merged.
head(new_totals_mean_m, 1)
# Save the merged dataframe as a .txt file.
write.table(new_totals_mean_m, "VVKAJ_Tot_mean_m.txt", sep="\t", row.names=F, quote=F)
# Load your totals if necessary - to be used as input for QC.
new_totals_mean_m <- read.table("VVKAJ_Tot_mean_m.txt", sep="\t", header=T)
#####
# Split your dataset to males and females because different thresholds apply for males and females.
new_totals_mean_m_M <- subset(new_totals_mean_m, Gender=="M")
dim(new_totals_mean_m_M)
new_totals_mean_m_F <- subset(new_totals_mean_m, Gender=="F")
dim(new_totals_mean_m_F)
# ---------------------------------------------------------------------------------------------------------------
### QC for males
# Define your totals dataset to be used as input.
QCtotals <- new_totals_mean_m_M
# Flag if KCAL is <650 or >5700 --> ask remove or not --> if yes, remove those rows
QCOutliers(input.data = QCtotals, target.colname = "KCAL", min = 650, max = 5700)
# If you find potential outlier(s) here, click "No", and view those
# total(s) with their other nutrient intake information by running the following;
KCAL_outliers <- subset(QCtotals, KCAL < 650 | KCAL > 5700)
# Sort the rows by KCAL and show only the specified variables.
KCAL_outliers[order(KCAL_outliers$KCAL, decreasing = T),
c('UserName', 'KCAL', 'FoodAmt', 'PROT', 'TFAT', 'CARB')]
# Flag if PROT is <10 or >240 --> ask remove or not --> if yes, remove those rows
QCOutliers(input.data = QCtotals, target.colname = "PROT", min = 25, max = 240)
# Flag if KCAL is <650 or >5700 --> ask remove or not --> if yes, remove those rows
QCOutliers(input.data = QCtotals, target.colname = "KCAL", min = 650, max = 5700)
# Flag if PROT is <10 or >240 --> ask remove or not --> if yes, remove those rows
QCOutliers(input.data = QCtotals, target.colname = "PROT", min = 25, max = 240)
# Flag if TFAT is <15 or >230 --> ask remove or not --> if yes, remove those rows
QCOutliers(input.data = QCtotals, target.colname = "TFAT", min = 25, max = 230)
# Flag if VC (Vitamin C) is <5 or >400 --> ask remove or not --> if yes, remove those rows
QCOutliers(input.data = QCtotals, target.colname = "VC", min = 5, max = 400)
# Name the males totals after QC.
QCed_M <- QCtotals
dim(QCed_M)
# ---------------------------------------------------------------------------------------------------------------
### QC for females
# Define your totals dataset to be used as input.
QCtotals <- new_totals_mean_m_F
# Flag if KCAL is <600 or >5700 --> ask remove or not --> if yes, remove those rows
QCOutliers(input.data = QCtotals, target.colname = "KCAL", min = 600, max = 4400)
# If you find potential outlier(s) here, click "No", and view those
# total(s) with their other nutrient intake information by running the following;
KCAL_outliers <- subset(QCtotals, KCAL < 600 | KCAL > 4400)
# Sort the rows by KCAL and show only the specified variables.
KCAL_outliers[order(KCAL_outliers$KCAL, decreasing = T),
c('UserName', 'KCAL', 'FoodAmt', 'PROT', 'TFAT', 'CARB')]
# Flag if PROT is <10 or >180 --> ask remove or not --> if yes, remove those rows
QCOutliers(input.data = QCtotals, target.colname = "PROT", min = 10, max = 180)
# Flag if TFAT is <15 or >185 --> ask remove or not --> if yes, remove those rows
QCOutliers(input.data = QCtotals, target.colname = "TFAT", min = 15, max = 185)
# Flag if VC (Vitamin C) is <5 or >350 --> ask remove or not --> if yes, remove those rows
QCOutliers(input.data = QCtotals, target.colname = "VC", min = 5, max = 350)
# Name the females totals after QC.
QCed_F <- QCtotals
dim(QCed_F)
# Combine the rows of M and F.
QCtotals_MF <- rbind(QCed_M, QCed_F)
# Save as a .txt file.
write.table(QCtotals_MF, "VVKAJ_Tot_mean_m_QCed_MF.txt", sep="\t", quote=F, row.names=F)
Comb <- read.delim("VVKAJ_Tot_mean_m_QCed.txt")
MF <- read.delim("VVKAJ_Tot_mean_m_QCed_MF.txt")
head(Comb[, c("UserName", "Gender", "Diet", "Waist.Circumference")])
head(MF[, c("UserName", "Gender", "Diet", "Waist.Circumference")])
mean(Comb$KCAL)
mean(MF$KCAL)
mean(Comb$FoodAmt)
mean(MF$FoodAmt)
# Among the individuals in new_totals_m, retain only those in QCtotals.
new_totals_m_QCed <- new_totals_m[ new_totals_m$UserName %in% QCtotals$UserName, ]
# Save as a .txt file. This will be the total for each of the "QC-ed" individuals for each day, to be
# used for clustering analyses.
write.table(new_totals_m_QCed, "VVKAJ_Tot_m_QCed.txt", sep="\t", quote=F, row.names=F)
unique(new_totals_m_QCed$UserName)
# Among the individuals in new_totals_m, retain only those in QCtotals.
new_totals_m_QCed <- new_totals_m[ new_totals_m$UserName %in% QCtotals_MF$UserName, ]
unique(new_totals_m_QCed$UserName)
# Save as a .txt file. This will be the total for each of the "QC-ed" individuals for each day, to be
# used for clustering analyses.
write.table(new_totals_m_QCed, "VVKAJ_Tot_m_QCed.txt", sep="\t", quote=F, row.names=F)
# Among the individuals in new_totals_m, pick up only those in QCtotals.
items_f_id_s_m_QCed <- items_f_id_s_m[ items_f_id_s_m$UserName %in% QCtotals_MF$UserName, ]
unique(items_f_id_s_m_QCed$UserName)
